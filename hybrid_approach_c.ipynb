{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173c16a1-f53b-42ed-982f-7df885541749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score, classification_report, confusion_matrix\n",
    "\n",
    "it = 10\n",
    "with open(f\"/home/stagiaire/D/R/metrics/MA{it}4.pkl\", 'rb') as f:\n",
    "    global_list = pickle.load(f)\n",
    "\n",
    "data = {}\n",
    "for i in range(1, 5):\n",
    "    root_dir = f\"/home/stagiaire/D/D/patchs/{i}\"\n",
    "    keys = {\"favelas\": 1, \"residential\": 0}\n",
    "    for folder in os.listdir(root_dir):\n",
    "        root_folder = os.path.join(root_dir, folder)\n",
    "        files = os.listdir(root_folder)\n",
    "        for file in files:\n",
    "            n = file.split('.')[0]\n",
    "            data[n] = keys[folder]\n",
    "labels_list = pd.DataFrame(list(data.items()), columns=['Id', 'Label'])\n",
    "labels_list = labels_list.set_index('Id')\n",
    "\n",
    "global_list = pd.merge(global_list, labels_list, left_index=True, right_index=True)\n",
    "\n",
    "for index, row in global_list.iterrows():\n",
    "    if not row['PredictC']:\n",
    "        global_list = global_list.drop(index)\n",
    "labels = global_list['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb5fe12-54a2-4715-a7da-ea00232e1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_list['PredictC_'] = global_list['PredictC'].apply(lambda x: [-1 if p == 0 else 1 for p in x])\n",
    "global_list['PredictA_'] = global_list['PredictA'].apply(lambda x: [-1 if p == 0 else 1 for p in x])\n",
    "\n",
    "def weighting(prop, pred):\n",
    "    return [np.abs(prop_i-0.5)*pred_i for prop_i, pred_i in zip(prop, pred)]\n",
    "    \n",
    "global_list['C'] = global_list.apply(lambda row: weighting(row['ProbaC'], row['PredictC_']), axis=1).tolist()\n",
    "global_list['A'] = global_list.apply(lambda row: weighting(row['ProbaA'], row['PredictA_']), axis=1).tolist()\n",
    "\n",
    "def merging(C, A, PC, PA):\n",
    "    return [(Ci + Ai)/(np.abs(PCi-0.5) + np.abs(PAi-0.5)) for Ci, Ai, PCi, PAi in zip(C, A, PC, PA)]\n",
    "\n",
    "global_list['F'] = global_list.apply(lambda row: merging(row['C'], row['A'], row['ProbaC'], row['ProbaA']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6336fcb5-ae59-4626-bfcf-d6ed1754614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard index:  63.2%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                191                 20\n",
      "Actual Class 1                 65                146\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       211\n",
      "           1       0.88      0.69      0.77       211\n",
      "\n",
      "    accuracy                           0.80       422\n",
      "   macro avg       0.81      0.80      0.80       422\n",
      "weighted avg       0.81      0.80      0.80       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  59.8%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                181                 30\n",
      "Actual Class 1                 67                144\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       211\n",
      "           1       0.83      0.68      0.75       211\n",
      "\n",
      "    accuracy                           0.77       422\n",
      "   macro avg       0.78      0.77      0.77       422\n",
      "weighted avg       0.78      0.77      0.77       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  64.3%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                195                 16\n",
      "Actual Class 1                 65                146\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       211\n",
      "           1       0.90      0.69      0.78       211\n",
      "\n",
      "    accuracy                           0.81       422\n",
      "   macro avg       0.83      0.81      0.81       422\n",
      "weighted avg       0.83      0.81      0.81       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  64.0%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                194                 17\n",
      "Actual Class 1                 65                146\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       211\n",
      "           1       0.90      0.69      0.78       211\n",
      "\n",
      "    accuracy                           0.81       422\n",
      "   macro avg       0.82      0.81      0.80       422\n",
      "weighted avg       0.82      0.81      0.80       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  62.6%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                187                 24\n",
      "Actual Class 1                 64                147\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81       211\n",
      "           1       0.86      0.70      0.77       211\n",
      "\n",
      "    accuracy                           0.79       422\n",
      "   macro avg       0.80      0.79      0.79       422\n",
      "weighted avg       0.80      0.79      0.79       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  62.0%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                185                 26\n",
      "Actual Class 1                 64                147\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80       211\n",
      "           1       0.85      0.70      0.77       211\n",
      "\n",
      "    accuracy                           0.79       422\n",
      "   macro avg       0.80      0.79      0.78       422\n",
      "weighted avg       0.80      0.79      0.78       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  62.2%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                189                 22\n",
      "Actual Class 1                 66                145\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       211\n",
      "           1       0.87      0.69      0.77       211\n",
      "\n",
      "    accuracy                           0.79       422\n",
      "   macro avg       0.80      0.79      0.79       422\n",
      "weighted avg       0.80      0.79      0.79       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  62.6%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                184                 27\n",
      "Actual Class 1                 62                149\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       211\n",
      "           1       0.85      0.71      0.77       211\n",
      "\n",
      "    accuracy                           0.79       422\n",
      "   macro avg       0.80      0.79      0.79       422\n",
      "weighted avg       0.80      0.79      0.79       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  62.5%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                190                 21\n",
      "Actual Class 1                 66                145\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       211\n",
      "           1       0.87      0.69      0.77       211\n",
      "\n",
      "    accuracy                           0.79       422\n",
      "   macro avg       0.81      0.79      0.79       422\n",
      "weighted avg       0.81      0.79      0.79       422\n",
      "\n",
      "\n",
      "\n",
      "Jaccard index:  60.8%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                190                 21\n",
      "Actual Class 1                 70                141\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.81       211\n",
      "           1       0.87      0.67      0.76       211\n",
      "\n",
      "    accuracy                           0.78       422\n",
      "   macro avg       0.80      0.78      0.78       422\n",
      "weighted avg       0.80      0.78      0.78       422\n",
      "\n",
      "\n",
      "Precision (mean, stdev): 87%, 2%\n",
      "Recall (mean, stdev): 69%, 1%\n",
      "F1-score (mean, stdev): 77%, 1%\n",
      "IoU (mean, stdev): 62%, 1%\n",
      "\n",
      "[[189.  22.]\n",
      " [ 65. 146.]]\n",
      "\n",
      "[[4. 4.]\n",
      " [2. 2.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "for i in range(10):\n",
    "    weighted_pred = global_list['F'].apply(lambda x: x[i]).tolist()\n",
    "    final_pred = [1 if p >= 0 else 0 for p in weighted_pred]\n",
    "    \n",
    "    J = jaccard_score(labels, final_pred)\n",
    "    CM = confusion_matrix(labels, final_pred)\n",
    "    dfCM = pd.DataFrame(CM, index=['Actual Class 0', 'Actual Class 1'], columns=['Predicted Class 0', 'Predicted Class 1'])\n",
    "    CR = classification_report(labels, final_pred)\n",
    "    \n",
    "    print(f\"\\nJaccard index: {J*100: 0.1f}%\\n\")\n",
    "    print(f\"\\n{dfCM}\\n\")\n",
    "    print(f\"\\n{CR}\\n\")\n",
    "    metrics.append([CM, CR, J])\n",
    "    \n",
    "from R import RGenerator\n",
    "report = RGenerator(metrics).report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840df308-a953-4181-9329-ddb7d1f6d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jaccard index:  65.1%\n",
      "\n",
      "\n",
      "                Predicted Class 0  Predicted Class 1\n",
      "Actual Class 0                150                 61\n",
      "Actual Class 1                 34                177\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76       211\n",
      "           1       0.74      0.84      0.79       211\n",
      "\n",
      "    accuracy                           0.77       422\n",
      "   macro avg       0.78      0.77      0.77       422\n",
      "weighted avg       0.78      0.77      0.77       422\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_list['medianC'] = (global_list['PredictC'].apply(statistics.median)).apply(lambda m: 1 if m == 0.5 else m)\n",
    "global_list['medianA'] = (global_list['PredictA'].apply(statistics.median)).apply(lambda m: 1 if m == 0.5 else m)\n",
    "global_list['stdevC'] = global_list['PredictC_'].apply(statistics.pstdev)\n",
    "global_list['stdevA'] = global_list['PredictA_'].apply(statistics.pstdev)\n",
    "\n",
    "global_list['F2'] = ((1-global_list['stdevC'])*global_list['medianC'].apply(lambda m: -1 if m == 0 else m)+(1-global_list['stdevA'])*global_list['medianA'].apply(lambda m: -1 if m == 0 else m))/(2-global_list['stdevC']-global_list['stdevA'])\n",
    "weighted_pred = global_list['F2'].tolist()\n",
    "final_pred = [1 if p >= 0 else 0 for p in weighted_pred]\n",
    "\n",
    "J = jaccard_score(labels, final_pred)\n",
    "CM = confusion_matrix(labels, final_pred)\n",
    "dfCM = pd.DataFrame(CM, index=['Actual Class 0', 'Actual Class 1'], columns=['Predicted Class 0', 'Predicted Class 1'])\n",
    "CR = classification_report(labels, final_pred)\n",
    "    \n",
    "print(f\"\\nJaccard index: {J*100: 0.1f}%\\n\")\n",
    "print(f\"\\n{dfCM}\\n\")\n",
    "print(f\"\\n{CR}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
